# 实验一 彩色空间转换实验
## 一.实验原理
### 1.YUV与RGB空间的相互转换
+ 由电视原理可知，亮度和色差信号的构成如下：
```
 Y ＝ 0.2990R + 0.5870G + 0.1140B
 R-Y＝0.7010R - 0.5870G - 0.1140B
 B-Y＝-0.2990R - 0.5870G + 0.8860B
```
**由于做差,R-Y的取值范围为[-255, 255],在编程的时候要注意加上128使0电平对应128**
+ 为了使色差信号的动态范围控制在0.5之间，需要进行归一化，对色差信号引入压缩系数。归一化后的色差信号为：
```
U＝-0.1684R - 0.3316G + 0.5B
V＝0.5R - 0.4187G - 0.0813B
```
+ yuv转rgb的公式如下
```
R = Y + 1.402V
G = Y - 0.344U - 0.714V
B = Y + 1.772U
```
### 2.码电平分配及数字表达式
+ 亮电平信号量化后码电平分配
```
在对分量信号进行8比特均匀量化时，共分为256个等间隔的量化级。
为了防止信号变动造成过载，在256级上端留20级，下端留16级作为信号超越动态范围的保护带。
```
+ 色差信号量化后码电平分配
```
色差信号经过归一化处理后，动态范围为-0.5－0.5，让色差零电平对应码电平128，色差信号总共占225个量化级。
在256级上端留15级，下端留16级作为信号超越动态范围的保护带。
```
+ 色度格式
```
4:2:0格式是指色差信号U，V的取样频率为亮度信号取样频率的四分之一，在水平方向和垂直方向上的取样点数均为Y的一半。
```
### 3.文件格式
+ rgb文件按照**B G R B G R**这样的格式存储，每个像素值一个字节，取值范围[0,255]

**在实际bmp文件中，数据的存储是最后一行的数据对应实际图片的第一行，所以在RGB转YUV的程序中需要考虑翻转情况**

+ yuv文件按照先存**Y**, 再存**U**, 然后存**V**， 每个像素值一个字节，取值范围[0,255]
## 二.实验步骤
+ 新建一个工程，并设置命令行参数， 工作目录
	![命令行参数设置](https://github.com/cucrui/Data-compression/blob/master/%E5%AE%9E%E9%AA%8C%E4%B8%80_YUV_RGB%E8%BD%AC%E6%8D%A2/imgs/%E8%AE%BE%E7%BD%AE.jpg)
+ 新建mian.cpp, yuv2rgb.cpp, yuv2rgb.h三个文件

	![文件](https://github.com/cucrui/Data-compression/blob/master/实验一_YUV_RGB转换/imgs/文件.png)
+ 关于yuv2rgb.cpp中的程序流程
	+ 	读入文件流
 	+ 	对u,v分量进行上采样得到4:4:4格式
	+ 	利用上述公式进行yuv转rgb
 	+  	将rgb数据流写入文件中
## 三.关键代码
1.main.cpp中将yuv数据写入yuvbuf中
```cpp
while (fread(yuvBuf, 1, (u_int)(frameWidth * frameHeight * 1.5), yuvFile)){
	yBuf = yuvBuf;		//分配yuv的起始地址
	uBuf = yuvBuf + (u_int)(frameWidth * frameHeight);										
	vBuf = uBuf + (u_int)(frameWidth * frameHeight * 0.25);										
	if(YUV2RGB(frameWidth, frameHeight, yBuf, uBuf, vBuf, rgbBuf, flip)){
		printf("error");
		return 0;
	}
	fwrite(rgbBuf, 1, frameWidth * frameHeight * 3, rgbFile);
	printf("\r...%d\n", ++videoFramesWritten);
}
printf("\n%u %ux%u video frames written\n", videoFramesWritten, frameWidth, frameHeight);
```
2.对读入的uv分量进行上采样
```cpp
int idx_row = 0, idx_col = 0, pos0, pos1, pos2, pos3, pos;
for(int row = 0; row < Y_DIM / 2; row++){
	for(int col = 0; col < X_DIM / 2; col++){
		pos = col + X_DIM / 2 * row;		//确定四个相邻像素在连续内存中的位置
		pos0 = idx_col + idx_row * X_DIM;												
		pos1 = idx_col + 1 + idx_row * X_DIM; 
		pos2 = idx_col + (idx_row + 1) * X_DIM;
		pos3 = idx_col + 1 + (idx_row + 1) * X_DIM;

		u_buffer[pos0] = sub_u_buf[pos];		//四个像素值相等
		u_buffer[pos1] = sub_u_buf[pos];
		u_buffer[pos2] = sub_u_buf[pos];
		u_buffer[pos3] = sub_u_buf[pos];

		v_buffer[pos0] = sub_v_buf[pos];
		v_buffer[pos1] = sub_v_buf[pos];
		v_buffer[pos2] = sub_v_buf[pos];
		v_buffer[pos3] = sub_v_buf[pos];

		if(idx_col + 2 == X_DIM){
			idx_row += 2;
			idx_col = 0; 
		} 
		else{
			idx_col += 2; 
		}
	}
}  
```
3.4:4:4的yuv转成rgb
```cpp
for(int i = 0, j = 0; i < size; i++){
		tem = (*y) + YUV_RGB1402[*v];		//有可能会超过[0,255]的取值范围
		rgb_out[j + 2] = tem > 255 ? 255 : (tem < 0 ? 0 : (unsigned char)tem);	
		tem = (*y) - YUV_RGB0344[*u] - YUV_RGB0714[*v];
		rgb_out[j + 1] = tem > 255 ? 255 : (tem < 0 ? 0 : (unsigned char)tem);
		tem = (*y) + YUV_RGB1772[*u];
		rgb_out[j] = tem > 255 ? 255 : (tem < 0 ? 0 : (unsigned char)tem);
		y++; u++; v++;
		j += 3;
}
```
## 四.实验结果
## 五.实验结论
